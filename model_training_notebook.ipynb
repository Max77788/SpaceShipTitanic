{"cells": [{"cell_type": "code", "metadata": {}, "source": "\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# 1. Splitting the dataset into predictor and target set\nX = data_encoded.drop(\"Transported\", axis=1)\ny = data_encoded[\"Transported\"]\n\n# 2. Splitting the data into training and test sets (75% training, 25% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Initializing the models\nmodels = {\n    \"Gaussian Naive Bayes\": GaussianNB(),\n    \"Multinomial Naive Bayes\": MultinomialNB(),\n    \"Bernoulli Naive Bayes\": BernoulliNB(),\n    \"Complement Naive Bayes\": ComplementNB(),\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Decision Tree Classifier\": DecisionTreeClassifier()\n}\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Function to calculate the required metrics\ndef get_metrics(y_true, y_pred):\n    return {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred),\n        \"Recall\": recall_score(y_true, y_pred),\n        \"F1 Score\": f1_score(y_true, y_pred)\n    }\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Storing the results for each model\nresults = {}\n\n# 3. Train and predict using each model\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    results[model_name] = get_metrics(y_test, y_pred)\n\nresults_df = pd.DataFrame(results).T\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Additional code for the subsequent models\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.linear_model import RidgeClassifier, Perceptron, PassiveAggressiveClassifier, SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Initializing all the additional models\nadditional_models = {\n    \"Ridge Classifier\": RidgeClassifier(),\n    \"Perceptron\": Perceptron(),\n    \"Passive Aggressive Classifier\": PassiveAggressiveClassifier(),\n    \"LinearSVC\": LinearSVC(max_iter=10000),\n    \"SVC\": SVC(),\n    \"Random Forest Classifier\": RandomForestClassifier(),\n    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n    \"Extra Trees Classifier\": ExtraTreesClassifier(),\n    \"AdaBoost Classifier\": AdaBoostClassifier(),\n    \"Bagging Classifier\": BaggingClassifier(),\n    \"MLP Classifier\": MLPClassifier(max_iter=1000),\n    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n    \"SGD Classifier\": SGDClassifier()\n}\n    ", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "\n# Storing the results for each additional model\nadditional_results = {}\n\n# Train and predict using each additional model\nfor model_name, model in additional_models.items():\n    try:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        additional_results[model_name] = get_metrics(y_test, y_pred)\n    except Exception as e:\n        additional_results[model_name] = {\"Error\": str(e)}\n\n# Combining results with previous models and creating the final dataframe\ncombined_results = {**results, **additional_results}\nresults_df_combined = pd.DataFrame(combined_results).T\n    ", "execution_count": null, "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 4}